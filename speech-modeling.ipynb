{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speech Modelling\n",
    "\n",
    "In this notebook we will explore acoustic modelling using the Gaussian Mixture Model or GMM. We will see the use of the GMM in voice activity detection and in speech recognition\n",
    "\n",
    "### Voice Activity Detection\n",
    "In this problem we aim to determine sections of the audio signal corresponding to speech.\n",
    "\n",
    "#### Data\n",
    "For the experiments, we use data from the [TensorFlow Speech Recognition Challenge](https://www.kaggle.com/c/tensorflow-speech-recognition-challenge/data). This dataset contains recordings of isolated words such as \"Yes\", \"No\", \"Up\", \"Down\", etc\n",
    "\n",
    "Before running the cell below, create the `data` directory in the same folder containing this notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#obtain the data and visualise\n",
    "import os\n",
    "import urllib.request\n",
    "import tarfile\n",
    "\n",
    "url = 'http://download.tensorflow.org/data/speech_commands_v0.01.tar.gz'\n",
    "data_files = os.listdir('data/')\n",
    "\n",
    "if 'speech_commands_v0.01.tar.gz' not in data_files:\n",
    "    print('Downloading...')\n",
    "    urllib.request.urlretrieve(url, 'data/speech_commands_v0.01.tar.gz')\n",
    "    print('Done!')\n",
    "else:\n",
    "    print('Data Available')\n",
    "    \n",
    "# unzip\n",
    " \n",
    "if 'yes' not in data_files:\n",
    "    try:    \n",
    "        tf = tarfile.open('data/speech_commands_v0.01.tar.gz')\n",
    "        tf.extractall('data/')\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation\n",
    "We now obtain a random file with the word \"yes\" and plot its waveform and spectrogram\n",
    "\n",
    "Install [librosa](https://github.com/librosa/librosa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import librosa\n",
    "import librosa.display\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "\n",
    "# set up speech processing parameters\n",
    "NFFT = 512  # 32 ms at 16kHz\n",
    "HOP_LENGTH = 256 \n",
    "NUM_MFCC = 13\n",
    "\n",
    "\n",
    "yes_files = os.listdir('data/yes')\n",
    "signal, sampling_rate = librosa.load('data/yes/' + random.choice(yes_files), sr=None) # use native sampling rate\n",
    "    \n",
    "# compute spectrogram\n",
    "spect = np.abs(librosa.stft(signal, n_fft=NFFT, hop_length=HOP_LENGTH))\n",
    "\n",
    "plt.figure()\n",
    "plt.subplot(211)\n",
    "librosa.display.specshow(librosa.amplitude_to_db(spect, ref=np.max),\n",
    "                         sr=sampling_rate,\n",
    "                         hop_length=HOP_LENGTH,\n",
    "                         y_axis='linear', \n",
    "                         x_axis='time')\n",
    "plt.title('Spectrogram of \"Yes\"')\n",
    "plt.xticks([])\n",
    "plt.xlabel('')\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.plot(np.arange(len(signal)) / sampling_rate, signal)\n",
    "plt.xlim([0, 1]);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voice activity detection\n",
    "VAD is a classification problem. For each speech frame, we seek to detemine whether the frame is speech or not. We will need to select features for our task.\n",
    "\n",
    "Two features we can start with are\n",
    "* energy\n",
    "* zero crossing rate\n",
    "\n",
    "The short time energy is computed as\n",
    "       \\begin{equation}\n",
    "        E_{\\hat{n}}=\\sum_{m=-\\infty}^\\infty (x[m]w[\\hat{n} - m])^2\n",
    "        \\end{equation}\n",
    "        \n",
    "and the ZCR is\n",
    "\\begin{equation}\n",
    "        Z_{\\hat{n}}=\\sum_{m=-\\infty}^\\infty0.5|\\mathrm{sgn}\\{x[m]\\} - \\mathrm{sgn}\\{x[m-1]\\}|w[\\hat{n} - m]\n",
    "       \\end{equation}\n",
    "Where    \n",
    "        \\begin{equation}\n",
    "\\mathrm{sgn}\\{x\\}=\\left\\{ \\begin{array}{ll}\n",
    "1 & x\\geq 0\\\\\n",
    "-1 & x<0\n",
    "\\end{array} \\right.\n",
    "\\end{equation}\n",
    "\n",
    "The signal is processed frame by frame by moving a window across the signal.\n",
    "\n",
    "\n",
    "## Exercise 1\n",
    "Write code to compute the short time energy of the signal. As input the function should take the signal, window size and overlap (or hop length) between segments. Do not use the inbuilt `librosa` functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "Using the short time energy function you have computed, plot the frame energy as a function of time on the same graph as the speech signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3\n",
    "\n",
    "Use `librosa` to compute the short time energy and compare it with your function. Comment on similarities and differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling\n",
    "\n",
    "We will work with the `energy` to build a voice activity detection system.\n",
    "\n",
    "### Exercise 4\n",
    "\n",
    "Plot a histogram of the log of the energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will attempt to fit a one dimensional GMM to the log energy.\n",
    "\n",
    "We will use `scikit-learn`. Installation instructions can be found [here](https://scikit-learn.org/stable/install.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace the line below with the appropriate value\n",
    "log_energy = np.zeros((len(signal),1))\n",
    "from sklearn import mixture\n",
    "gmm = mixture.GaussianMixture(n_components=2)\n",
    "\n",
    "gmm.fit(log_energy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the component means\n",
    "gmm.means_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The component with the highest mean corresponds to the speech.\n",
    "\n",
    "### Exercise 5\n",
    "Get the mean corresponding to the speech component and predict the category of each frame. Finally plot the speech signal as well as an indicator funtion that is 1 over a speech frame and 0 over a non-speech frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
